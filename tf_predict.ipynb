{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from random import random, sample, seed\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "import resource\n",
    "import gc\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, concatenate, Activation\n",
    "from tensorflow.keras.layers import Masking, Dropout, Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import CSVLogger, TensorBoard, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_path = 'data/submissions.csv'\n",
    "embeddings_path = 'data/glove.6B.50d.txt'\n",
    "max_features = 40000\n",
    "maxlen = 20 # max input length\n",
    "batch_size = 32\n",
    "embedding_dims = 50 # word embedding dim\n",
    "meta_embedding_dims = 64 # metadata embedding dim\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "hours = []\n",
    "minutes = []\n",
    "dayofweeks = []\n",
    "dayofyears = []\n",
    "is_top_submission = []\n",
    "\n",
    "max_rows = 16000\n",
    "\n",
    "with open(data_path, 'r', encoding=\"latin1\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    i = 0\n",
    "    for submission in reader:\n",
    "#         if i >= max_rows:\n",
    "#             break\n",
    "#         i += 1\n",
    "        titles.append(submission['title'])\n",
    "        hours.append(submission['hour'])\n",
    "        minutes.append(submission['minute'])\n",
    "        dayofweeks.append(submission['dayofweek'])\n",
    "        dayofyears.append(submission['dayofyear'])\n",
    "        is_top_submission.append(submission['is_top_submission'])\n",
    "            \n",
    "titles = np.array(titles)\n",
    "hours = np.array(hours, dtype=int)\n",
    "minutes = np.array(minutes, dtype=int)\n",
    "dayofweeks = np.array(dayofweeks, dtype=int)\n",
    "dayofyears = np.array(dayofyears, dtype=int)\n",
    "is_top_submission = np.array(is_top_submission, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(max_rows//2, max_rows):\n",
    "#     is_top_submission[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer(max_features)\n",
    "word_tokenizer.fit_on_texts(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_tf = word_tokenizer.texts_to_sequences(titles)\n",
    "titles_tf = tf.keras.preprocessing.sequence.pad_sequences(titles_tf, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = {}\n",
    "\n",
    "with open(embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.strip().split(\" \")\n",
    "        vec = np.array(line_split[1:], dtype=float)\n",
    "        word = line_split[0]\n",
    "        embedding_vectors[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = np.zeros((max_features + 1, 50))\n",
    "\n",
    "for word, i in word_tokenizer.word_index.items():\n",
    "\n",
    "    embedding_vector = embedding_vectors.get(word)\n",
    "    if embedding_vector is not None and i <= max_features:\n",
    "        weights_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero based year\n",
    "dayofyears_tf = dayofyears - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# sess.close()\n",
    "tf.keras.backend.clear_session()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    titles_input = Input(shape=(maxlen,), name='titles_input')\n",
    "    titles_embedding = Embedding(max_features + 1, embedding_dims, weights=[weights_matrix])(titles_input)\n",
    "    titles_pooling = GlobalAveragePooling1D()(titles_embedding)\n",
    "    \n",
    "    aux_output = Dense(1, activation='sigmoid', name='aux_out')(titles_input)\n",
    "    \n",
    "    hours_input = Input(shape=(1,), name='hours_input')\n",
    "    hours_embedding = Embedding(24, meta_embedding_dims)(hours_input)\n",
    "    hours_reshape = Reshape((meta_embedding_dims,))(hours_embedding)\n",
    "\n",
    "    dayofweeks_input = Input(shape=(1,), name='dayofweeks_input')\n",
    "    dayofweeks_embedding = Embedding(7, meta_embedding_dims)(dayofweeks_input)\n",
    "    dayofweeks_reshape = Reshape((meta_embedding_dims,))(dayofweeks_embedding)\n",
    "\n",
    "    minutes_input = Input(shape=(1,), name='minutes_input')\n",
    "    minutes_embedding = Embedding(60, meta_embedding_dims)(minutes_input)\n",
    "    minutes_reshape = Reshape((meta_embedding_dims,))(minutes_embedding)\n",
    "\n",
    "    dayofyears_input = Input(shape=(1,), name='dayofyears_input')\n",
    "    dayofyears_embedding = Embedding(366, meta_embedding_dims)(dayofyears_input)\n",
    "    dayofyears_reshape = Reshape((meta_embedding_dims,))(dayofyears_embedding)\n",
    "    \n",
    "    merged = concatenate([titles_pooling, hours_reshape, dayofweeks_reshape, minutes_reshape, dayofyears_reshape])\n",
    "\n",
    "    hidden_1 = Dense(256, activation='relu')(merged)\n",
    "    hidden_1 = BatchNormalization()(hidden_1)\n",
    "\n",
    "    main_output = Dense(1, activation='sigmoid', name='main_out')(hidden_1)\n",
    "    \n",
    "    model = Model(inputs=[titles_input,\n",
    "                      hours_input,\n",
    "                      dayofweeks_input,\n",
    "                      minutes_input,\n",
    "                      dayofyears_input], outputs=[main_output, aux_output])\n",
    "    \n",
    "#     model = Model(inputs=[titles_input], outputs=[aux_output])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "titles_input (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hours_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofweeks_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "minutes_input (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofyears_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 50)       2000050     titles_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 64)        1536        hours_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 64)        448         dayofweeks_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 64)        3840        minutes_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 64)        23424       dayofyears_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 50)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 64)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 306)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          78592       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_out (Dense)                (None, 1)            257         batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "aux_out (Dense)                 (None, 1)            21          titles_input[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,109,192\n",
      "Trainable params: 2,108,680\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(123)\n",
    "split = 0.2\n",
    "\n",
    "# returns randomized indices with no repeats\n",
    "idx = sample(range(titles_tf.shape[0]), titles_tf.shape[0])\n",
    "\n",
    "titles_tf = titles_tf[idx, :]\n",
    "hours = hours[idx]\n",
    "dayofweeks = dayofweeks[idx]\n",
    "minutes = minutes[idx]\n",
    "dayofyears_tf = dayofyears_tf[idx]\n",
    "is_top_submission = is_top_submission[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        gc.collect()\n",
    "        process = psutil.Process(os.getpid())\n",
    "        print('\\n memory: {} \\n'.format(process.memory_info()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(maxlen,)))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/10\n",
      "12736/12800 [============================>.] - ETA: 0s - loss: 8.6208 - main_out_loss: 0.7172 - aux_out_loss: 7.9036 - main_out_acc: 0.5158 - aux_out_acc: 0.5054\n",
      " memory: pmem(rss=824684544, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277263872, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 9s 726us/sample - loss: 8.6258 - main_out_loss: 0.7170 - aux_out_loss: 7.9088 - main_out_acc: 0.5163 - aux_out_acc: 0.5051 - val_loss: 8.5882 - val_main_out_loss: 0.7001 - val_aux_out_loss: 7.8881 - val_main_out_acc: 0.4963 - val_aux_out_acc: 0.5066\n",
      "Epoch 2/10\n",
      "12672/12800 [============================>.] - ETA: 0s - loss: 8.5758 - main_out_loss: 0.6818 - aux_out_loss: 7.8940 - main_out_acc: 0.5607 - aux_out_acc: 0.5066\n",
      " memory: pmem(rss=825225216, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277304832, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 527us/sample - loss: 8.5870 - main_out_loss: 0.6821 - aux_out_loss: 7.9049 - main_out_acc: 0.5605 - aux_out_acc: 0.5059 - val_loss: 8.6256 - val_main_out_loss: 0.7470 - val_aux_out_loss: 7.8786 - val_main_out_acc: 0.4959 - val_aux_out_acc: 0.5063\n",
      "Epoch 3/10\n",
      "12768/12800 [============================>.] - ETA: 0s - loss: 8.5467 - main_out_loss: 0.6531 - aux_out_loss: 7.8937 - main_out_acc: 0.6100 - aux_out_acc: 0.5067\n",
      " memory: pmem(rss=825225216, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277394944, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 528us/sample - loss: 8.5407 - main_out_loss: 0.6530 - aux_out_loss: 7.8878 - main_out_acc: 0.6102 - aux_out_acc: 0.5071 - val_loss: 8.5666 - val_main_out_loss: 0.7292 - val_aux_out_loss: 7.8374 - val_main_out_acc: 0.5213 - val_aux_out_acc: 0.5103\n",
      "Epoch 4/10\n",
      "12768/12800 [============================>.] - ETA: 0s - loss: 8.4416 - main_out_loss: 0.5960 - aux_out_loss: 7.8456 - main_out_acc: 0.6726 - aux_out_acc: 0.5081\n",
      " memory: pmem(rss=825225216, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277399040, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 528us/sample - loss: 8.4423 - main_out_loss: 0.5963 - aux_out_loss: 7.8460 - main_out_acc: 0.6724 - aux_out_acc: 0.5081 - val_loss: 8.6483 - val_main_out_loss: 0.7932 - val_aux_out_loss: 7.8552 - val_main_out_acc: 0.5184 - val_aux_out_acc: 0.5053\n",
      "Epoch 5/10\n",
      "12736/12800 [============================>.] - ETA: 0s - loss: 8.3706 - main_out_loss: 0.5224 - aux_out_loss: 7.8482 - main_out_acc: 0.7381 - aux_out_acc: 0.5074\n",
      " memory: pmem(rss=825225216, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277431808, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 526us/sample - loss: 8.3630 - main_out_loss: 0.5228 - aux_out_loss: 7.8403 - main_out_acc: 0.7377 - aux_out_acc: 0.5079 - val_loss: 8.7251 - val_main_out_loss: 0.8795 - val_aux_out_loss: 7.8456 - val_main_out_acc: 0.5291 - val_aux_out_acc: 0.5066\n",
      "Epoch 6/10\n",
      "12672/12800 [============================>.] - ETA: 0s - loss: 8.2688 - main_out_loss: 0.4534 - aux_out_loss: 7.8153 - main_out_acc: 0.7825 - aux_out_acc: 0.5099\n",
      " memory: pmem(rss=825495552, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277530112, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 528us/sample - loss: 8.2658 - main_out_loss: 0.4540 - aux_out_loss: 7.8118 - main_out_acc: 0.7823 - aux_out_acc: 0.5100 - val_loss: 8.8509 - val_main_out_loss: 0.9839 - val_aux_out_loss: 7.8670 - val_main_out_acc: 0.5188 - val_aux_out_acc: 0.5053\n",
      "Epoch 7/10\n",
      "12704/12800 [============================>.] - ETA: 0s - loss: 8.1816 - main_out_loss: 0.3919 - aux_out_loss: 7.7898 - main_out_acc: 0.8180 - aux_out_acc: 0.5113\n",
      " memory: pmem(rss=825495552, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277530112, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 527us/sample - loss: 8.1814 - main_out_loss: 0.3921 - aux_out_loss: 7.7894 - main_out_acc: 0.8180 - aux_out_acc: 0.5113 - val_loss: 8.9299 - val_main_out_loss: 1.0766 - val_aux_out_loss: 7.8533 - val_main_out_acc: 0.5109 - val_aux_out_acc: 0.5053\n",
      "Epoch 8/10\n",
      "12672/12800 [============================>.] - ETA: 0s - loss: 8.1097 - main_out_loss: 0.3373 - aux_out_loss: 7.7724 - main_out_acc: 0.8493 - aux_out_acc: 0.5113\n",
      " memory: pmem(rss=825495552, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277530112, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 526us/sample - loss: 8.1009 - main_out_loss: 0.3374 - aux_out_loss: 7.7634 - main_out_acc: 0.8495 - aux_out_acc: 0.5118 - val_loss: 9.0070 - val_main_out_loss: 1.1878 - val_aux_out_loss: 7.8193 - val_main_out_acc: 0.5197 - val_aux_out_acc: 0.5081\n",
      "Epoch 9/10\n",
      "12704/12800 [============================>.] - ETA: 0s - loss: 8.0341 - main_out_loss: 0.2843 - aux_out_loss: 7.7497 - main_out_acc: 0.8801 - aux_out_acc: 0.5123\n",
      " memory: pmem(rss=825495552, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277562880, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 528us/sample - loss: 8.0387 - main_out_loss: 0.2856 - aux_out_loss: 7.7531 - main_out_acc: 0.8793 - aux_out_acc: 0.5121 - val_loss: 9.1258 - val_main_out_loss: 1.3086 - val_aux_out_loss: 7.8173 - val_main_out_acc: 0.5150 - val_aux_out_acc: 0.5094\n",
      "Epoch 10/10\n",
      "12672/12800 [============================>.] - ETA: 0s - loss: 7.9921 - main_out_loss: 0.2452 - aux_out_loss: 7.7469 - main_out_acc: 0.8980 - aux_out_acc: 0.5118\n",
      " memory: pmem(rss=825495552, vms=4748656640, shared=119640064, text=2322432, lib=0, data=1277562880, dirty=0) \n",
      "\n",
      "12800/12800 [==============================] - 7s 524us/sample - loss: 7.9932 - main_out_loss: 0.2467 - aux_out_loss: 7.7465 - main_out_acc: 0.8972 - aux_out_acc: 0.5118 - val_loss: 9.1983 - val_main_out_loss: 1.4385 - val_aux_out_loss: 7.7598 - val_main_out_acc: 0.5175 - val_aux_out_acc: 0.5103\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([titles_tf, hours, dayofweeks, minutes, dayofyears_tf], [is_top_submission, is_top_submission],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=split,\n",
    "          callbacks=[MemoryCallback()])\n",
    "# history = model.fit([titles_tf], [is_top_submission],\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_split=split,\n",
    "#           callbacks=[MemoryCallback()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

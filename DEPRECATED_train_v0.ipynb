{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, concatenate, Activation, Dropout, BatchNormalization, Reshape\n",
    "from tensorflow.keras.callbacks import TensorBoard, Callback, ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "model_name = 'model_dropout0.5_no_earlystop_lossweights1.0,0.2'\n",
    "embeddings_path = 'data/glove.6B.50d.txt'\n",
    "load_existing_model = False # load existing model\n",
    "model_save_path = 'models/{}.hdf5'.format(model_name)\n",
    "max_features = 40000\n",
    "maxlen = 20 # max input length\n",
    "batch_size = 32\n",
    "embedding_dims = 50 # word embedding dim\n",
    "meta_embedding_dims = 64 # metadata embedding dim\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('loaded_data.pickle', 'rb') as file:\n",
    "    payload = pickle.load(file)\n",
    "\n",
    "for k in payload.keys():\n",
    "    exec('{} = payload[\"{}\"]'.format(k, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load glove vectors to bootstrap embeddings if not loading existing model\n",
    "if not load_existing_model:\n",
    "    embedding_vectors = {}\n",
    "    weights_matrix = np.zeros((max_features + 1, 50))\n",
    "\n",
    "    with open(embeddings_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line_split = line.strip().split(\" \")\n",
    "            vec = np.array(line_split[1:], dtype=float)\n",
    "            word = line_split[0]\n",
    "            embedding_vectors[word] = vec\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embedding_vectors.get(word)\n",
    "        if embedding_vector is not None and i <= max_features:\n",
    "            weights_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(load_existing):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    titles_input = Input(shape=(maxlen,), name='titles_input')\n",
    "    if load_existing:\n",
    "        titles_embedding = Embedding(max_features + 1, embedding_dims)(titles_input)\n",
    "    else:\n",
    "        titles_embedding = Embedding(max_features + 1, embedding_dims, weights=[weights_matrix])(titles_input)\n",
    "    titles_pooling = GlobalAveragePooling1D()(titles_embedding)\n",
    "    \n",
    "    aux_output = Dense(1, activation='sigmoid', name='aux_out')(titles_pooling)\n",
    "    \n",
    "    hours_input = Input(shape=(1,), name='hours_input')\n",
    "    hours_embedding = Embedding(24, meta_embedding_dims)(hours_input)\n",
    "    hours_reshape = Reshape((meta_embedding_dims,))(hours_embedding)\n",
    "\n",
    "    dayofweeks_input = Input(shape=(1,), name='dayofweeks_input')\n",
    "    dayofweeks_embedding = Embedding(7, meta_embedding_dims)(dayofweeks_input)\n",
    "    dayofweeks_reshape = Reshape((meta_embedding_dims,))(dayofweeks_embedding)\n",
    "\n",
    "    minutes_input = Input(shape=(1,), name='minutes_input')\n",
    "    minutes_embedding = Embedding(60, meta_embedding_dims)(minutes_input)\n",
    "    minutes_reshape = Reshape((meta_embedding_dims,))(minutes_embedding)\n",
    "\n",
    "    dayofyears_input = Input(shape=(1,), name='dayofyears_input')\n",
    "    dayofyears_embedding = Embedding(366, meta_embedding_dims)(dayofyears_input)\n",
    "    dayofyears_reshape = Reshape((meta_embedding_dims,))(dayofyears_embedding)\n",
    "    \n",
    "    merged = concatenate([titles_pooling, hours_reshape, dayofweeks_reshape, minutes_reshape, dayofyears_reshape])\n",
    "\n",
    "    hidden_1 = Dense(256, activation='relu')(merged)\n",
    "    hidden_1 = BatchNormalization()(hidden_1)\n",
    "    hidden_1 = Dropout(.5)(hidden_1)\n",
    "\n",
    "    main_output = Dense(1, activation='sigmoid', name='main_out')(hidden_1)\n",
    "    \n",
    "    model = Model(inputs=[titles_input,\n",
    "                      hours_input,\n",
    "                      dayofweeks_input,\n",
    "                      minutes_input,\n",
    "                      dayofyears_input], outputs=[main_output, aux_output])\n",
    "    \n",
    "    if load_existing:\n",
    "        model.load_weights(model_save_path)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'],\n",
    "                  loss_weights=[1, 0.2])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "titles_input (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hours_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofweeks_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "minutes_input (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofyears_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 50)       2000050     titles_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 64)        1536        hours_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 64)        448         dayofweeks_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 64)        3840        minutes_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 64)        23424       dayofyears_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 50)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 64)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 306)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          78592       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "main_out (Dense)                (None, 1)            257         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aux_out (Dense)                 (None, 1)            51          global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 2,109,222\n",
      "Trainable params: 2,108,710\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(load_existing_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to hopefully keep memory leaks down\n",
    "class MemoryCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        gc.collect()\n",
    "        process = psutil.Process(os.getpid())\n",
    "        print('\\n Memory usage: {} \\n'.format(process.memory_info()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/scalars/{}_{}\".format(model_name,\n",
    "                                      datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "model_checkpoint_path = 'models/checkpoints/'+ model_name +'.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "\n",
    "callbacks = [\n",
    "    MemoryCallback(),\n",
    "    TensorBoard(log_dir=log_dir),\n",
    "    ModelCheckpoint(model_checkpoint_path)\n",
    "#     EarlyStopping(monitor='val_loss', patience=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1118162 samples, validate on 139770 samples\n",
      "WARNING:tensorflow:From /home/david/anaconda3/envs/capstone/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.7000 - main_out_loss: 0.5823 - aux_out_loss: 0.5885 - main_out_acc: 0.6714 - aux_out_acc: 0.6680\n",
      " Memory usage: 1382109184 \n",
      "\n",
      "1118162/1118162 [==============================] - 699s 625us/sample - loss: 0.7000 - main_out_loss: 0.5823 - aux_out_loss: 0.5885 - main_out_acc: 0.6714 - aux_out_acc: 0.6680 - val_loss: 0.6847 - val_main_out_loss: 0.5681 - val_aux_out_loss: 0.5830 - val_main_out_acc: 0.6786 - val_aux_out_acc: 0.6671\n",
      "Epoch 2/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.6830 - main_out_loss: 0.5673 - aux_out_loss: 0.5786 - main_out_acc: 0.6778 - aux_out_acc: 0.6707\n",
      " Memory usage: 1401745408 \n",
      "\n",
      "1118162/1118162 [==============================] - 687s 615us/sample - loss: 0.6830 - main_out_loss: 0.5673 - aux_out_loss: 0.5786 - main_out_acc: 0.6778 - aux_out_acc: 0.6707 - val_loss: 0.6826 - val_main_out_loss: 0.5662 - val_aux_out_loss: 0.5823 - val_main_out_acc: 0.6807 - val_aux_out_acc: 0.6702\n",
      "Epoch 3/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.6784 - main_out_loss: 0.5632 - aux_out_loss: 0.5760 - main_out_acc: 0.6798 - aux_out_acc: 0.6726\n",
      " Memory usage: 1405374464 \n",
      "\n",
      "1118162/1118162 [==============================] - 687s 615us/sample - loss: 0.6784 - main_out_loss: 0.5632 - aux_out_loss: 0.5760 - main_out_acc: 0.6798 - aux_out_acc: 0.6726 - val_loss: 0.6824 - val_main_out_loss: 0.5659 - val_aux_out_loss: 0.5824 - val_main_out_acc: 0.6796 - val_aux_out_acc: 0.6700\n",
      "Epoch 4/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.6753 - main_out_loss: 0.5604 - aux_out_loss: 0.5745 - main_out_acc: 0.6817 - aux_out_acc: 0.6735\n",
      " Memory usage: 1411325952 \n",
      "\n",
      "1118162/1118162 [==============================] - 708s 633us/sample - loss: 0.6753 - main_out_loss: 0.5604 - aux_out_loss: 0.5745 - main_out_acc: 0.6817 - aux_out_acc: 0.6735 - val_loss: 0.6818 - val_main_out_loss: 0.5652 - val_aux_out_loss: 0.5829 - val_main_out_acc: 0.6802 - val_aux_out_acc: 0.6698\n",
      "Epoch 5/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.6729 - main_out_loss: 0.5582 - aux_out_loss: 0.5734 - main_out_acc: 0.6829 - aux_out_acc: 0.6743\n",
      " Memory usage: 1413468160 \n",
      "\n",
      "1118162/1118162 [==============================] - 704s 629us/sample - loss: 0.6729 - main_out_loss: 0.5582 - aux_out_loss: 0.5734 - main_out_acc: 0.6829 - aux_out_acc: 0.6743 - val_loss: 0.6818 - val_main_out_loss: 0.5652 - val_aux_out_loss: 0.5829 - val_main_out_acc: 0.6801 - val_aux_out_acc: 0.6702\n",
      "Epoch 6/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6711 - main_out_loss: 0.5565 - aux_out_loss: 0.5726 - main_out_acc: 0.6841 - aux_out_acc: 0.6750\n",
      " Memory usage: 1415090176 \n",
      "\n",
      "1118162/1118162 [==============================] - 703s 629us/sample - loss: 0.6711 - main_out_loss: 0.5566 - aux_out_loss: 0.5726 - main_out_acc: 0.6841 - aux_out_acc: 0.6750 - val_loss: 0.6819 - val_main_out_loss: 0.5653 - val_aux_out_loss: 0.5829 - val_main_out_acc: 0.6800 - val_aux_out_acc: 0.6697\n",
      "Epoch 7/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.6691 - main_out_loss: 0.5548 - aux_out_loss: 0.5720 - main_out_acc: 0.6846 - aux_out_acc: 0.6754\n",
      " Memory usage: 1418854400 \n",
      "\n",
      "1118162/1118162 [==============================] - 702s 628us/sample - loss: 0.6691 - main_out_loss: 0.5548 - aux_out_loss: 0.5720 - main_out_acc: 0.6846 - aux_out_acc: 0.6754 - val_loss: 0.6823 - val_main_out_loss: 0.5656 - val_aux_out_loss: 0.5836 - val_main_out_acc: 0.6783 - val_aux_out_acc: 0.6663\n",
      "Epoch 8/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6677 - main_out_loss: 0.5535 - aux_out_loss: 0.5715 - main_out_acc: 0.6865 - aux_out_acc: 0.6759\n",
      " Memory usage: 1426423808 \n",
      "\n",
      "1118162/1118162 [==============================] - 699s 626us/sample - loss: 0.6678 - main_out_loss: 0.5535 - aux_out_loss: 0.5715 - main_out_acc: 0.6865 - aux_out_acc: 0.6759 - val_loss: 0.6821 - val_main_out_loss: 0.5655 - val_aux_out_loss: 0.5831 - val_main_out_acc: 0.6796 - val_aux_out_acc: 0.6684\n",
      "Epoch 9/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.6664 - main_out_loss: 0.5522 - aux_out_loss: 0.5710 - main_out_acc: 0.6873 - aux_out_acc: 0.6764\n",
      " Memory usage: 1428025344 \n",
      "\n",
      "1118162/1118162 [==============================] - 695s 621us/sample - loss: 0.6664 - main_out_loss: 0.5522 - aux_out_loss: 0.5710 - main_out_acc: 0.6873 - aux_out_acc: 0.6764 - val_loss: 0.6818 - val_main_out_loss: 0.5651 - val_aux_out_loss: 0.5833 - val_main_out_acc: 0.6789 - val_aux_out_acc: 0.6685\n",
      "Epoch 10/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.6648 - main_out_loss: 0.5506 - aux_out_loss: 0.5707 - main_out_acc: 0.6882 - aux_out_acc: 0.6766\n",
      " Memory usage: 1429377024 \n",
      "\n",
      "1118162/1118162 [==============================] - 695s 621us/sample - loss: 0.6648 - main_out_loss: 0.5506 - aux_out_loss: 0.5707 - main_out_acc: 0.6883 - aux_out_acc: 0.6766 - val_loss: 0.6829 - val_main_out_loss: 0.5661 - val_aux_out_loss: 0.5838 - val_main_out_acc: 0.6789 - val_aux_out_acc: 0.6692\n",
      "Epoch 11/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6635 - main_out_loss: 0.5494 - aux_out_loss: 0.5703 - main_out_acc: 0.6893 - aux_out_acc: 0.6769\n",
      " Memory usage: 1430978560 \n",
      "\n",
      "1118162/1118162 [==============================] - 709s 634us/sample - loss: 0.6635 - main_out_loss: 0.5494 - aux_out_loss: 0.5703 - main_out_acc: 0.6893 - aux_out_acc: 0.6769 - val_loss: 0.6840 - val_main_out_loss: 0.5670 - val_aux_out_loss: 0.5846 - val_main_out_acc: 0.6783 - val_aux_out_acc: 0.6690\n",
      "Epoch 12/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6622 - main_out_loss: 0.5482 - aux_out_loss: 0.5700 - main_out_acc: 0.6904 - aux_out_acc: 0.6773\n",
      " Memory usage: 1432334336 \n",
      "\n",
      "1118162/1118162 [==============================] - 709s 634us/sample - loss: 0.6622 - main_out_loss: 0.5482 - aux_out_loss: 0.5700 - main_out_acc: 0.6904 - aux_out_acc: 0.6773 - val_loss: 0.6835 - val_main_out_loss: 0.5666 - val_aux_out_loss: 0.5843 - val_main_out_acc: 0.6777 - val_aux_out_acc: 0.6678\n",
      "Epoch 13/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6609 - main_out_loss: 0.5470 - aux_out_loss: 0.5698 - main_out_acc: 0.6914 - aux_out_acc: 0.6777\n",
      " Memory usage: 1433935872 \n",
      "\n",
      "1118162/1118162 [==============================] - 693s 620us/sample - loss: 0.6609 - main_out_loss: 0.5470 - aux_out_loss: 0.5698 - main_out_acc: 0.6914 - aux_out_acc: 0.6777 - val_loss: 0.6859 - val_main_out_loss: 0.5687 - val_aux_out_loss: 0.5860 - val_main_out_acc: 0.6780 - val_aux_out_acc: 0.6698\n",
      "Epoch 14/20\n",
      "1118080/1118162 [============================>.] - ETA: 0s - loss: 0.6594 - main_out_loss: 0.5455 - aux_out_loss: 0.5695 - main_out_acc: 0.6923 - aux_out_acc: 0.6779\n",
      " Memory usage: 1439346688 \n",
      "\n",
      "1118162/1118162 [==============================] - 713s 638us/sample - loss: 0.6594 - main_out_loss: 0.5455 - aux_out_loss: 0.5695 - main_out_acc: 0.6923 - aux_out_acc: 0.6779 - val_loss: 0.6857 - val_main_out_loss: 0.5687 - val_aux_out_loss: 0.5852 - val_main_out_acc: 0.6755 - val_aux_out_acc: 0.6665\n",
      "Epoch 15/20\n",
      "1118144/1118162 [============================>.] - ETA: 0s - loss: 0.6584 - main_out_loss: 0.5445 - aux_out_loss: 0.5693 - main_out_acc: 0.6935 - aux_out_acc: 0.6781\n",
      " Memory usage: 1449058304 \n",
      "\n",
      "1118162/1118162 [==============================] - 715s 639us/sample - loss: 0.6584 - main_out_loss: 0.5445 - aux_out_loss: 0.5693 - main_out_acc: 0.6935 - aux_out_acc: 0.6781 - val_loss: 0.6856 - val_main_out_loss: 0.5688 - val_aux_out_loss: 0.5843 - val_main_out_acc: 0.6770 - val_aux_out_acc: 0.6673\n",
      "Epoch 16/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6569 - main_out_loss: 0.5431 - aux_out_loss: 0.5691 - main_out_acc: 0.6939 - aux_out_acc: 0.6785\n",
      " Memory usage: 1456631808 \n",
      "\n",
      "1118162/1118162 [==============================] - 691s 618us/sample - loss: 0.6569 - main_out_loss: 0.5431 - aux_out_loss: 0.5690 - main_out_acc: 0.6939 - aux_out_acc: 0.6785 - val_loss: 0.6873 - val_main_out_loss: 0.5703 - val_aux_out_loss: 0.5849 - val_main_out_acc: 0.6733 - val_aux_out_acc: 0.6659\n",
      "Epoch 17/20\n",
      "1118080/1118162 [============================>.] - ETA: 0s - loss: 0.6559 - main_out_loss: 0.5421 - aux_out_loss: 0.5689 - main_out_acc: 0.6947 - aux_out_acc: 0.6783\n",
      " Memory usage: 1458774016 \n",
      "\n",
      "1118162/1118162 [==============================] - 683s 611us/sample - loss: 0.6559 - main_out_loss: 0.5421 - aux_out_loss: 0.5689 - main_out_acc: 0.6947 - aux_out_acc: 0.6783 - val_loss: 0.6873 - val_main_out_loss: 0.5702 - val_aux_out_loss: 0.5852 - val_main_out_acc: 0.6758 - val_aux_out_acc: 0.6687\n",
      "Epoch 18/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6548 - main_out_loss: 0.5410 - aux_out_loss: 0.5687 - main_out_acc: 0.6964 - aux_out_acc: 0.6787\n",
      " Memory usage: 1460137984 \n",
      "\n",
      "1118162/1118162 [==============================] - 683s 610us/sample - loss: 0.6548 - main_out_loss: 0.5410 - aux_out_loss: 0.5687 - main_out_acc: 0.6964 - aux_out_acc: 0.6787 - val_loss: 0.6891 - val_main_out_loss: 0.5719 - val_aux_out_loss: 0.5861 - val_main_out_acc: 0.6766 - val_aux_out_acc: 0.6691\n",
      "Epoch 19/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6534 - main_out_loss: 0.5397 - aux_out_loss: 0.5685 - main_out_acc: 0.6967 - aux_out_acc: 0.6788\n",
      " Memory usage: 1461219328 \n",
      "\n",
      "1118162/1118162 [==============================] - 702s 628us/sample - loss: 0.6534 - main_out_loss: 0.5397 - aux_out_loss: 0.5685 - main_out_acc: 0.6967 - aux_out_acc: 0.6788 - val_loss: 0.6914 - val_main_out_loss: 0.5739 - val_aux_out_loss: 0.5876 - val_main_out_acc: 0.6743 - val_aux_out_acc: 0.6700\n",
      "Epoch 20/20\n",
      "1118112/1118162 [============================>.] - ETA: 0s - loss: 0.6523 - main_out_loss: 0.5386 - aux_out_loss: 0.5684 - main_out_acc: 0.6977 - aux_out_acc: 0.6788\n",
      " Memory usage: 1462571008 \n",
      "\n",
      "1118162/1118162 [==============================] - 685s 613us/sample - loss: 0.6523 - main_out_loss: 0.5386 - aux_out_loss: 0.5684 - main_out_acc: 0.6977 - aux_out_acc: 0.6788 - val_loss: 0.6917 - val_main_out_loss: 0.5744 - val_aux_out_loss: 0.5866 - val_main_out_acc: 0.6748 - val_aux_out_acc: 0.6683\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=[titles_train, hours_train, weekdays_train, minutes_train, dates_train],\n",
    "    y=[is_top_submission_train, is_top_submission_train],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([titles_val, hours_val, weekdays_val, minutes_val, dates_val],\n",
    "                     [is_top_submission_val, is_top_submission_val]),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model.save_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

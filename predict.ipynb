{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from random import random, sample, seed\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Embedding, GlobalAveragePooling1D, concatenate, Activation\n",
    "from keras.layers.core import Masking, Dropout, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/submissions.csv'\n",
    "embeddings_path = 'data/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "hours = []\n",
    "minutes = []\n",
    "dayofweeks = []\n",
    "dayofyears = []\n",
    "is_top_submission = []\n",
    "\n",
    "max_rows = 16000 # my crappy computer can't handle too many rows\n",
    "\n",
    "with open(data_path, 'r', encoding=\"latin1\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    i = 0\n",
    "    for submission in reader:\n",
    "        if i >= max_rows:\n",
    "            break\n",
    "        i += 1\n",
    "        titles.append(submission['title'])\n",
    "        hours.append(submission['hour'])\n",
    "        minutes.append(submission['minute'])\n",
    "        dayofweeks.append(submission['dayofweek'])\n",
    "        dayofyears.append(submission['dayofyear'])\n",
    "        is_top_submission.append(submission['is_top_submission'])\n",
    "            \n",
    "titles = np.array(titles)\n",
    "hours = np.array(hours, dtype=int)\n",
    "minutes = np.array(minutes, dtype=int)\n",
    "dayofweeks = np.array(dayofweeks, dtype=int)\n",
    "dayofyears = np.array(dayofyears, dtype=int)\n",
    "is_top_submission = np.array(is_top_submission, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['People who downloaded their Google data and went through it, what were the most unsettling things you found out they had stored about you?'\n",
      " \"Have you ever felt you don't know/have forgotten who you really are? That you've spent years just adapting to surroundings to make life easier and don't know what's the real you anymore? If so, how did you overcome this?\"]\n",
      "(16000,)\n",
      "[22  3]\n",
      "[45 53]\n",
      "[3 4]\n",
      "[219 206]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "print(titles[0:2])\n",
    "print(titles.shape)\n",
    "print(hours[0:2])\n",
    "print(minutes[0:2])\n",
    "print(dayofweeks[0:2])\n",
    "print(dayofyears[0:2])\n",
    "print(is_top_submission[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My computer can't handle the actual top submissions.  Just make the second half of the \"top\" top submissions the real \"top\" submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_rows//2, max_rows):\n",
    "    is_top_submission[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.mean(is_top_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('people', 1907), ('who', 1483), ('downloaded', 3), ('their', 430), ('google', 35), ('d\n",
      "{'you': 1, 'what': 2, 'the': 3, 'to': 4, 'a': 5, 'of': 6, 'your': 7, 'is': 8, 'do': 9, 'in': 10, 'th\n",
      "11462\n"
     ]
    }
   ],
   "source": [
    "max_features = 40000\n",
    "\n",
    "word_tokenizer = Tokenizer(max_features)\n",
    "word_tokenizer.fit_on_texts(titles)\n",
    "\n",
    "print(str(word_tokenizer.word_counts)[0:100])\n",
    "print(str(word_tokenizer.word_index)[0:100])\n",
    "print(len(word_tokenizer.word_counts))   # true word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 23, 3681, 73, 641, 3126, 12, 566, 286, 16, 2, 49, 3, 27, 2181, 96, 1, 207, 58, 62, 57, 4540, 33, 1]\n"
     ]
    }
   ],
   "source": [
    "titles_tf = word_tokenizer.texts_to_sequences(titles)\n",
    "\n",
    "print(titles_tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 641 3126   12  566  286   16    2   49    3   27 2181   96    1  207\n",
      "   58   62   57 4540   33    1]\n"
     ]
    }
   ],
   "source": [
    "maxlen = 20\n",
    "titles_tf = sequence.pad_sequences(titles_tf, maxlen=maxlen)\n",
    "\n",
    "print(titles_tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0919e-03  3.3324e-01  3.5743e-01 -5.4041e-01  8.2032e-01 -4.9391e-01\n",
      " -3.2588e-01  1.9972e-03 -2.3829e-01  3.5554e-01 -6.0655e-01  9.8932e-01\n",
      " -2.1786e-01  1.1236e-01  1.1494e+00  7.3284e-01  5.1182e-01  2.9287e-01\n",
      "  2.8388e-01 -1.3590e+00 -3.7951e-01  5.0943e-01  7.0710e-01  6.2941e-01\n",
      "  1.0534e+00 -2.1756e+00 -1.3204e+00  4.0001e-01  1.5741e+00 -1.6600e+00\n",
      "  3.7721e+00  8.6949e-01 -8.0439e-01  1.8390e-01 -3.4332e-01  1.0714e-02\n",
      "  2.3969e-01  6.6748e-02  7.0117e-01 -7.3702e-01  2.0877e-01  1.1564e-01\n",
      " -1.5190e-01  8.5908e-01  2.2620e-01  1.6519e-01  3.6309e-01 -4.5697e-01\n",
      " -4.8969e-02  1.1316e+00]\n"
     ]
    }
   ],
   "source": [
    "embedding_vectors = {}\n",
    "\n",
    "with open(embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.strip().split(\" \")\n",
    "        vec = np.array(line_split[1:], dtype=float)\n",
    "        word = line_split[0]\n",
    "        embedding_vectors[word] = vec\n",
    "        \n",
    "print(embedding_vectors['you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [-1.0919e-03  3.3324e-01  3.5743e-01 -5.4041e-01  8.2032e-01 -4.9391e-01\n",
      "  -3.2588e-01  1.9972e-03 -2.3829e-01  3.5554e-01 -6.0655e-01  9.8932e-01\n",
      "  -2.1786e-01  1.1236e-01  1.1494e+00  7.3284e-01  5.1182e-01  2.9287e-01\n",
      "   2.8388e-01 -1.3590e+00 -3.7951e-01  5.0943e-01  7.0710e-01  6.2941e-01\n",
      "   1.0534e+00 -2.1756e+00 -1.3204e+00  4.0001e-01  1.5741e+00 -1.6600e+00\n",
      "   3.7721e+00  8.6949e-01 -8.0439e-01  1.8390e-01 -3.4332e-01  1.0714e-02\n",
      "   2.3969e-01  6.6748e-02  7.0117e-01 -7.3702e-01  2.0877e-01  1.1564e-01\n",
      "  -1.5190e-01  8.5908e-01  2.2620e-01  1.6519e-01  3.6309e-01 -4.5697e-01\n",
      "  -4.8969e-02  1.1316e+00]]\n"
     ]
    }
   ],
   "source": [
    "weights_matrix = np.zeros((max_features + 1, 50))\n",
    "\n",
    "for word, i in word_tokenizer.word_index.items():\n",
    "\n",
    "    embedding_vector = embedding_vectors.get(word)\n",
    "    if embedding_vector is not None and i <= max_features:\n",
    "        weights_matrix[i] = embedding_vector\n",
    "\n",
    "# index 0 vector should be all zeroes, index 1 vector should be the same one as above\n",
    "print(weights_matrix[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218 205 220 209 234 190 233 224 206 151]\n"
     ]
    }
   ],
   "source": [
    "dayofyears_tf = dayofyears - 1\n",
    "\n",
    "print(dayofyears_tf[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/david/.conda/envs/capstone/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "titles_input = Input(shape=(maxlen,), name='titles_input')\n",
    "titles_embedding = Embedding(max_features + 1, embedding_dims, weights=[weights_matrix])(titles_input)\n",
    "titles_pooling = GlobalAveragePooling1D()(titles_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_output = Dense(1, activation='sigmoid', name='aux_out')(titles_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_embedding_dims = 64\n",
    "\n",
    "hours_input = Input(shape=(1,), name='hours_input')\n",
    "hours_embedding = Embedding(24, meta_embedding_dims)(hours_input)\n",
    "hours_reshape = Reshape((meta_embedding_dims,))(hours_embedding)\n",
    "\n",
    "dayofweeks_input = Input(shape=(1,), name='dayofweeks_input')\n",
    "dayofweeks_embedding = Embedding(7, meta_embedding_dims)(dayofweeks_input)\n",
    "dayofweeks_reshape = Reshape((meta_embedding_dims,))(dayofweeks_embedding)\n",
    "\n",
    "minutes_input = Input(shape=(1,), name='minutes_input')\n",
    "minutes_embedding = Embedding(60, meta_embedding_dims)(minutes_input)\n",
    "minutes_reshape = Reshape((meta_embedding_dims,))(minutes_embedding)\n",
    "\n",
    "dayofyears_input = Input(shape=(1,), name='dayofyears_input')\n",
    "dayofyears_embedding = Embedding(366, meta_embedding_dims)(dayofyears_input)\n",
    "dayofyears_reshape = Reshape((meta_embedding_dims,))(dayofyears_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = concatenate([titles_pooling, hours_reshape, dayofweeks_reshape, minutes_reshape, dayofyears_reshape])\n",
    "\n",
    "hidden_1 = Dense(256, activation='relu')(merged)\n",
    "hidden_1 = BatchNormalization()(hidden_1)\n",
    "\n",
    "main_output = Dense(1, activation='sigmoid', name='main_out')(hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "titles_input (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hours_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofweeks_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "minutes_input (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofyears_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 50)       2000050     titles_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 64)        1536        hours_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 64)        448         dayofweeks_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 64)        3840        minutes_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 64)        23424       dayofyears_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 64)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 306)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          78592       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_out (Dense)                (None, 1)            257         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "aux_out (Dense)                 (None, 1)            51          global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,109,222\n",
      "Trainable params: 2,108,710\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[titles_input,\n",
    "                      hours_input,\n",
    "                      dayofweeks_input,\n",
    "                      minutes_input,\n",
    "                      dayofyears_input], outputs=[main_output, aux_output])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              loss_weights=[1, 0.2])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(123)\n",
    "split = 0.2\n",
    "\n",
    "# returns randomized indices with no repeats\n",
    "idx = sample(range(titles_tf.shape[0]), titles_tf.shape[0])\n",
    "\n",
    "titles_tf = titles_tf[idx, :]\n",
    "hours = hours[idx]\n",
    "dayofweeks = dayofweeks[idx]\n",
    "minutes = minutes[idx]\n",
    "dayofyears_tf = dayofyears_tf[idx]\n",
    "is_top_submission = is_top_submission[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49531250000000004\n"
     ]
    }
   ],
   "source": [
    "print(1 - np.mean(is_top_submission[:(int(titles_tf.shape[0] * split))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/david/.conda/envs/capstone/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/20\n",
      "12800/12800 [==============================] - 12s 935us/step - loss: 0.8582 - main_out_loss: 0.7185 - aux_out_loss: 0.6984 - main_out_accuracy: 0.5161 - aux_out_accuracy: 0.4971 - val_loss: 0.8367 - val_main_out_loss: 0.6975 - val_aux_out_loss: 0.6958 - val_main_out_accuracy: 0.5094 - val_aux_out_accuracy: 0.4884\n",
      "Epoch 2/20\n",
      "12800/12800 [==============================] - 10s 816us/step - loss: 0.8245 - main_out_loss: 0.6859 - aux_out_loss: 0.6930 - main_out_accuracy: 0.5596 - aux_out_accuracy: 0.5156 - val_loss: 0.8667 - val_main_out_loss: 0.7278 - val_aux_out_loss: 0.6945 - val_main_out_accuracy: 0.4950 - val_aux_out_accuracy: 0.5022\n",
      "Epoch 3/20\n",
      "12800/12800 [==============================] - 11s 855us/step - loss: 0.7962 - main_out_loss: 0.6583 - aux_out_loss: 0.6894 - main_out_accuracy: 0.6059 - aux_out_accuracy: 0.5379 - val_loss: 0.8827 - val_main_out_loss: 0.7438 - val_aux_out_loss: 0.6944 - val_main_out_accuracy: 0.5222 - val_aux_out_accuracy: 0.5131\n",
      "Epoch 4/20\n",
      "12800/12800 [==============================] - 11s 849us/step - loss: 0.7386 - main_out_loss: 0.6017 - aux_out_loss: 0.6843 - main_out_accuracy: 0.6698 - aux_out_accuracy: 0.5627 - val_loss: 0.9293 - val_main_out_loss: 0.7905 - val_aux_out_loss: 0.6943 - val_main_out_accuracy: 0.5109 - val_aux_out_accuracy: 0.5053\n",
      "Epoch 5/20\n",
      "12800/12800 [==============================] - 10s 776us/step - loss: 0.6678 - main_out_loss: 0.5325 - aux_out_loss: 0.6766 - main_out_accuracy: 0.7266 - aux_out_accuracy: 0.6011 - val_loss: 1.0317 - val_main_out_loss: 0.8927 - val_aux_out_loss: 0.6949 - val_main_out_accuracy: 0.5209 - val_aux_out_accuracy: 0.5072\n",
      "Epoch 6/20\n",
      "12800/12800 [==============================] - 11s 882us/step - loss: 0.5952 - main_out_loss: 0.4618 - aux_out_loss: 0.6675 - main_out_accuracy: 0.7795 - aux_out_accuracy: 0.6280 - val_loss: 1.0988 - val_main_out_loss: 0.9597 - val_aux_out_loss: 0.6955 - val_main_out_accuracy: 0.5116 - val_aux_out_accuracy: 0.5131\n",
      "Epoch 7/20\n",
      "12800/12800 [==============================] - 10s 798us/step - loss: 0.5319 - main_out_loss: 0.4005 - aux_out_loss: 0.6571 - main_out_accuracy: 0.8155 - aux_out_accuracy: 0.6592 - val_loss: 1.1847 - val_main_out_loss: 1.0453 - val_aux_out_loss: 0.6968 - val_main_out_accuracy: 0.5169 - val_aux_out_accuracy: 0.5081\n",
      "Epoch 8/20\n",
      "12800/12800 [==============================] - 9s 733us/step - loss: 0.4702 - main_out_loss: 0.3408 - aux_out_loss: 0.6467 - main_out_accuracy: 0.8512 - aux_out_accuracy: 0.6766 - val_loss: 1.2623 - val_main_out_loss: 1.1225 - val_aux_out_loss: 0.6991 - val_main_out_accuracy: 0.5147 - val_aux_out_accuracy: 0.5063\n",
      "Epoch 9/20\n",
      "12800/12800 [==============================] - 10s 804us/step - loss: 0.4182 - main_out_loss: 0.2910 - aux_out_loss: 0.6360 - main_out_accuracy: 0.8752 - aux_out_accuracy: 0.6938 - val_loss: 1.4182 - val_main_out_loss: 1.2780 - val_aux_out_loss: 0.7009 - val_main_out_accuracy: 0.5172 - val_aux_out_accuracy: 0.5075\n",
      "Epoch 10/20\n",
      "12800/12800 [==============================] - 10s 796us/step - loss: 0.3742 - main_out_loss: 0.2491 - aux_out_loss: 0.6252 - main_out_accuracy: 0.8972 - aux_out_accuracy: 0.7072 - val_loss: 1.5317 - val_main_out_loss: 1.3913 - val_aux_out_loss: 0.7024 - val_main_out_accuracy: 0.5113 - val_aux_out_accuracy: 0.5106\n",
      "Epoch 11/20\n",
      "12800/12800 [==============================] - 10s 796us/step - loss: 0.3326 - main_out_loss: 0.2097 - aux_out_loss: 0.6144 - main_out_accuracy: 0.9167 - aux_out_accuracy: 0.7216 - val_loss: 1.6528 - val_main_out_loss: 1.5118 - val_aux_out_loss: 0.7053 - val_main_out_accuracy: 0.5147 - val_aux_out_accuracy: 0.5097\n",
      "Epoch 12/20\n",
      "12800/12800 [==============================] - 9s 728us/step - loss: 0.3035 - main_out_loss: 0.1827 - aux_out_loss: 0.6040 - main_out_accuracy: 0.9278 - aux_out_accuracy: 0.7284 - val_loss: 1.7617 - val_main_out_loss: 1.6199 - val_aux_out_loss: 0.7093 - val_main_out_accuracy: 0.5228 - val_aux_out_accuracy: 0.5172\n",
      "Epoch 13/20\n",
      "12800/12800 [==============================] - 9s 731us/step - loss: 0.2689 - main_out_loss: 0.1502 - aux_out_loss: 0.5935 - main_out_accuracy: 0.9436 - aux_out_accuracy: 0.7357 - val_loss: 1.8621 - val_main_out_loss: 1.7196 - val_aux_out_loss: 0.7125 - val_main_out_accuracy: 0.5241 - val_aux_out_accuracy: 0.5138\n",
      "Epoch 14/20\n",
      "12800/12800 [==============================] - 9s 729us/step - loss: 0.2473 - main_out_loss: 0.1306 - aux_out_loss: 0.5836 - main_out_accuracy: 0.9513 - aux_out_accuracy: 0.7477 - val_loss: 2.0382 - val_main_out_loss: 1.8949 - val_aux_out_loss: 0.7167 - val_main_out_accuracy: 0.5278 - val_aux_out_accuracy: 0.5122\n",
      "Epoch 15/20\n",
      "12800/12800 [==============================] - 9s 731us/step - loss: 0.2310 - main_out_loss: 0.1162 - aux_out_loss: 0.5739 - main_out_accuracy: 0.9558 - aux_out_accuracy: 0.7480 - val_loss: 2.2526 - val_main_out_loss: 2.1087 - val_aux_out_loss: 0.7198 - val_main_out_accuracy: 0.5256 - val_aux_out_accuracy: 0.5109\n",
      "Epoch 16/20\n",
      "12800/12800 [==============================] - 9s 730us/step - loss: 0.2149 - main_out_loss: 0.1021 - aux_out_loss: 0.5638 - main_out_accuracy: 0.9628 - aux_out_accuracy: 0.7594 - val_loss: 2.3248 - val_main_out_loss: 2.1799 - val_aux_out_loss: 0.7243 - val_main_out_accuracy: 0.5256 - val_aux_out_accuracy: 0.5091\n",
      "Epoch 17/20\n",
      "12800/12800 [==============================] - 10s 796us/step - loss: 0.2039 - main_out_loss: 0.0931 - aux_out_loss: 0.5540 - main_out_accuracy: 0.9663 - aux_out_accuracy: 0.7634 - val_loss: 2.3629 - val_main_out_loss: 2.2169 - val_aux_out_loss: 0.7301 - val_main_out_accuracy: 0.5269 - val_aux_out_accuracy: 0.5109\n",
      "Epoch 18/20\n",
      "12800/12800 [==============================] - 11s 893us/step - loss: 0.1908 - main_out_loss: 0.0818 - aux_out_loss: 0.5448 - main_out_accuracy: 0.9710 - aux_out_accuracy: 0.7652 - val_loss: 2.4967 - val_main_out_loss: 2.3496 - val_aux_out_loss: 0.7353 - val_main_out_accuracy: 0.5297 - val_aux_out_accuracy: 0.5075\n",
      "Epoch 19/20\n",
      "12800/12800 [==============================] - 12s 907us/step - loss: 0.1915 - main_out_loss: 0.0843 - aux_out_loss: 0.5358 - main_out_accuracy: 0.9683 - aux_out_accuracy: 0.7705 - val_loss: 2.6563 - val_main_out_loss: 2.5082 - val_aux_out_loss: 0.7406 - val_main_out_accuracy: 0.5253 - val_aux_out_accuracy: 0.5103\n",
      "Epoch 20/20\n",
      "12800/12800 [==============================] - 11s 854us/step - loss: 0.1815 - main_out_loss: 0.0761 - aux_out_loss: 0.5267 - main_out_accuracy: 0.9712 - aux_out_accuracy: 0.7749 - val_loss: 2.7053 - val_main_out_loss: 2.5562 - val_aux_out_loss: 0.7453 - val_main_out_accuracy: 0.5213 - val_aux_out_accuracy: 0.5100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa1761770b8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([titles_tf, hours, dayofweeks, minutes, dayofyears_tf], [is_top_submission, is_top_submission],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=split, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text, maxlen):\n",
    "    encoded = word_tokenizer.texts_to_sequences([text])\n",
    "    return sequence.pad_sequences(encoded, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.9999597]], dtype=float32), array([[0.7188623]], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Which movie's plot would drastically change if you removed a letter from its title?\"\n",
    "encoded_text = encode_text(input_text, maxlen)\n",
    "input_hour = np.array([15])\n",
    "input_minute = np.array([46])\n",
    "input_dayofweek = np.array([1])\n",
    "input_dayofyear = np.array([16 - 1])\n",
    "\n",
    "model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
